{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is our 2-stage testing script (binary and multiclass)\n",
    "\n",
    "Author: Wesley\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a custom transformer that allows us to reduce the feature sets for each classifier appropriately.\n",
    "\n",
    "Necessary since we're making them all part of a StackingClassifier and each one uses a different feature set.\n",
    "\"\"\"\n",
    "class FeatureReducer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_list=None):\n",
    "        self.feature_list = feature_list\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if self.feature_list is None:\n",
    "            return X\n",
    "        \n",
    "        else:\n",
    "            return X.loc[:, self.feature_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and get binary and multiclass y columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENIGN     79997\n",
      "TFTP        6667\n",
      "Syn         6667\n",
      "UDP         6667\n",
      "DNS         6667\n",
      "UDP-lag     6666\n",
      "LDAP        6666\n",
      "Portmap     6666\n",
      "SSDP        6666\n",
      "NTP         6666\n",
      "NetBIOS     6666\n",
      "MSSQL       6666\n",
      "SNMP        6666\n",
      "Name:  Label, dtype: int64\n",
      "BENIGN     19999\n",
      "SSDP        1667\n",
      "NetBIOS     1667\n",
      "NTP         1667\n",
      "LDAP        1667\n",
      "UDP-lag     1667\n",
      "SNMP        1667\n",
      "MSSQL       1667\n",
      "Portmap     1667\n",
      "UDP         1666\n",
      "TFTP        1666\n",
      "Syn         1666\n",
      "DNS         1666\n",
      "Name:  Label, dtype: int64\n",
      "LDAP       13333\n",
      "DNS        13333\n",
      "Portmap    13333\n",
      "UDP        13333\n",
      "MSSQL      13333\n",
      "UDP-lag    13333\n",
      "Syn        13333\n",
      "NetBIOS    13333\n",
      "TFTP       13333\n",
      "SSDP       13332\n",
      "NTP        13332\n",
      "SNMP       13332\n",
      "Name:  Label, dtype: int64\n",
      "SNMP       3334\n",
      "SSDP       3334\n",
      "NTP        3334\n",
      "Portmap    3333\n",
      "NetBIOS    3333\n",
      "UDP-lag    3333\n",
      "MSSQL      3333\n",
      "LDAP       3333\n",
      "DNS        3333\n",
      "UDP        3333\n",
      "TFTP       3333\n",
      "Syn        3333\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "binary_train = pd.read_csv(\"binary_train.csv\")\n",
    "binary_test = pd.read_csv(\"binary_test.csv\")\n",
    "\n",
    "multiclass_train = pd.read_csv(\"multiclass_train.csv\")\n",
    "multiclass_test = pd.read_csv(\"multiclass_test.csv\")\n",
    "\n",
    "print(binary_train[\" Label\"].value_counts())\n",
    "print(binary_test[\" Label\"].value_counts())\n",
    "print(multiclass_train[\" Label\"].value_counts())\n",
    "print(multiclass_test[\" Label\"].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split and encode data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text labels from the encoding will be passed to classification report so we can interpret our results more easily.\n",
      "\n",
      "Binary Label Encodings (in order of digits 0 -> 1): \n",
      "['BENIGN', 'ATTACK']\n",
      "\n",
      "Multiclass Label Encodings (in order of digits 0 -> n): \n",
      "['DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']\n"
     ]
    }
   ],
   "source": [
    "bin_y_train = binary_train[\" Label\"].copy()\n",
    "bin_x_train = binary_train.drop([\" Label\"], axis=1)\n",
    "\n",
    "bin_y_test = binary_test[\" Label\"].copy()\n",
    "bin_x_test = binary_test.drop([\" Label\"], axis=1)\n",
    "\n",
    "bin_y_train = [0 if x==\"BENIGN\" else 1 for x in bin_y_train.values]\n",
    "bin_y_test = [0 if x==\"BENIGN\" else 1 for x in bin_y_test.values]\n",
    "\n",
    "print(\"The text labels from the encoding will be passed to classification report so we can interpret our results more easily.\\n\")\n",
    "binary_labels = [\"BENIGN\", \"ATTACK\"]\n",
    "\n",
    "print(\"Binary Label Encodings (in order of digits 0 -> 1): \")\n",
    "print(binary_labels)\n",
    "\n",
    "multi_y_train = multiclass_train[\" Label\"].copy()\n",
    "multi_x_train = multiclass_train.drop([\" Label\"], axis=1)\n",
    "\n",
    "multi_y_test = multiclass_test[\" Label\"].copy()\n",
    "multi_x_test = multiclass_test.drop([\" Label\"], axis=1)\n",
    "\n",
    "# Encode attack labels to int and save as array to be used later.\n",
    "le = LabelEncoder()\n",
    "\n",
    "multi_y_train = le.fit_transform(multi_y_train.values)\n",
    "multi_y_test = le.transform(multi_y_test.values)\n",
    "\n",
    "multiclass_labels = []\n",
    "print(\"\\nMulticlass Label Encodings (in order of digits 0 -> n): \")\n",
    "for i in range(0, len(list(set(list(multi_y_test))))):\n",
    "    multiclass_labels.append(le.inverse_transform([i])[0])\n",
    "\n",
    "print(multiclass_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a binary model\n",
    "stage_1 = keras.models.load_model('CNN_binary_final.h5')\n",
    "\n",
    "# Load a multiclass model\n",
    "\n",
    "# Hardcoded feature sets from tuning results.\n",
    "dt_features = [' Protocol', ' Flow Duration', 'Total Length of Fwd Packets', ' Fwd Packet Length Max', ' Fwd Packet Length Min', ' Fwd Packet Length Mean', ' Fwd Packet Length Std', 'Bwd Packet Length Max', ' Bwd Packet Length Min', ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s', ' Flow IAT Std', ' Flow IAT Max', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', 'Bwd IAT Total', ' Bwd IAT Min', 'Fwd PSH Flags', 'Fwd Packets/s', ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance', ' RST Flag Count', ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count', ' Down/Up Ratio', ' Average Packet Size', ' Avg Fwd Segment Size', ' Avg Bwd Segment Size', ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', 'Idle Mean', ' Idle Max', ' Idle Min', ' Inbound', ' Fwd Header Length', ' Fwd Header Length.1', ' min_seg_size_forward', ' Total Fwd Packets', 'Subflow Fwd Packets', ' act_data_pkt_fwd']\n",
    "lr_features = [' Protocol', ' Flow Duration', 'Total Length of Fwd Packets', ' Fwd Packet Length Max', ' Fwd Packet Length Min', ' Fwd Packet Length Mean', ' Fwd Packet Length Std', ' Bwd Packet Length Mean', 'Flow Bytes/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', 'Fwd Packets/s', ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance', ' ACK Flag Count', ' Average Packet Size', ' Avg Fwd Segment Size', ' Avg Bwd Segment Size', ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', ' act_data_pkt_fwd', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min']\n",
    "rf_features = [' Protocol', ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets', 'Total Length of Fwd Packets', ' Total Length of Bwd Packets', ' Fwd Packet Length Max', ' Fwd Packet Length Min', ' Fwd Packet Length Mean', ' Fwd Packet Length Std', 'Bwd Packet Length Max', ' Bwd Packet Length Mean', 'Flow Bytes/s', ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance', ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count', ' Down/Up Ratio', ' Average Packet Size', ' Avg Fwd Segment Size', ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', ' Subflow Bwd Packets', 'Init_Win_bytes_forward', ' Init_Win_bytes_backward', ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min', ' Inbound']\n",
    "\n",
    "# Use the custom transformer to reduce the feature sets for each classifier appropriately.\n",
    "clf_knn = KNeighborsClassifier(algorithm = 'kd_tree', n_neighbors=47, weights = 'distance')\n",
    "clf_dt = make_pipeline(FeatureReducer(feature_list=dt_features),DecisionTreeClassifier(random_state=42, criterion = 'gini', max_depth = 19, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 3))\n",
    "clf_lr = make_pipeline(FeatureReducer(feature_list=lr_features), StandardScaler(), LogisticRegression(random_state=42, C = 4602.593009396766, max_iter = 240))\n",
    "clf_rf = make_pipeline(FeatureReducer(feature_list=rf_features), RandomForestClassifier(criterion = 'entropy', max_depth = 65, max_features = 'sqrt', min_samples_leaf = 2, min_samples_split = 18, n_estimators = 478, random_state=42))\n",
    "\n",
    "# Load the estimators into a list.\n",
    "estimators = [(\"knn\",clf_knn),(\"dt\",clf_dt),(\"lr\",clf_lr),(\"rf\",clf_rf)]\n",
    "\n",
    "# Intialize the stacking classifier (finally)\n",
    "stage_2 = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1 Prediction (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "scal = StandardScaler()\n",
    "scal = scal.fit(bin_x_train)\n",
    "bin_x_test_reshaped = scal.transform(bin_x_test)\n",
    "y_pred = stage_1.predict(bin_x_test_reshaped)\n",
    "y_pred = [1 if x>=0.5 else 0 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN   0.999650  0.999900  0.999775     19999\n",
      "      ATTACK   0.999900  0.999650  0.999775     20000\n",
      "\n",
      "    accuracy                       0.999775     39999\n",
      "   macro avg   0.999775  0.999775  0.999775     39999\n",
      "weighted avg   0.999775  0.999775  0.999775     39999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(bin_y_test, y_pred, digits=6, target_names=binary_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housekeeping to prepare the dataset for 2nd stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\icarus\\AppData\\Local\\Temp\\ipykernel_15676\\2310080828.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_rem['binary_pred'] = X_rem['binary_pred'].replace([0], -1)\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframe out of binary predictions and multiclass labels that can be used to compare them later.\n",
    "X_agg = bin_x_test.copy()\n",
    "X_agg[\"binary_pred\"] = y_pred.copy()\n",
    "X_agg[\" Label\"] = binary_test[\" Label\"].copy()\n",
    "#X_agg[\" Label\"] = le.transform(X_agg[\" Label\"].values)\n",
    "X_agg.loc[~X_agg[\" Label\"].isin(le.classes_),\" Label\"] = -1 \n",
    "X_agg.loc[X_agg[\" Label\"].isin(le.classes_),\" Label\"] = le.transform(X_agg[\" Label\"][X_agg[\" Label\"].isin(le.classes_)])\n",
    "\n",
    "# Slice out the portions that we've identified as benign and replace their label with that of the multiclass benign label for comparison later.\n",
    "X_rem = X_agg[X_agg[\"binary_pred\"] == 0]\n",
    "X_rem['binary_pred'] = X_rem['binary_pred'].replace([0], -1)\n",
    "\n",
    "# Slice out the portions we've labeled as attack for 2nd stage classification.\n",
    "X_mult = X_agg[X_agg[\"binary_pred\"] == 1]\n",
    "X_mult = X_mult.drop([\"binary_pred\"], axis = 1)\n",
    "y_mult = X_mult[\" Label\"].values.copy()\n",
    "\n",
    "X_mult = X_mult.drop([\" Label\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd stage prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Fit the stacking classifier\n",
    "stage_2.fit(multi_x_train, multi_y_train)\n",
    "\n",
    "y_pred2 = stage_2.predict(X_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([1135, 1862, 1664, 1668, 1108, 2275, 1997, 1971,  953, 1656, 1458,\n",
      "       2248], dtype=int64))\n",
      "(array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([   2, 1665, 1667, 1667, 1664, 1667, 1666, 1667, 1666, 1666, 1665,\n",
      "       1666, 1667], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_pred2, return_counts=True))\n",
    "print(np.unique(list(y_mult), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']\n",
      "['BENIGN', 'DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']\n"
     ]
    }
   ],
   "source": [
    "print(multiclass_labels)\n",
    "multiclass_labels_add = [\"BENIGN\"]\n",
    "multiclass_labels_add.extend(multiclass_labels)\n",
    "print(multiclass_labels_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN   0.000000  0.000000  0.000000         2\n",
      "         DNS   0.791189  0.539339  0.641429      1665\n",
      "        LDAP   0.623523  0.696461  0.657977      1667\n",
      "       MSSQL   0.954327  0.952609  0.953467      1667\n",
      "         NTP   0.996403  0.998798  0.997599      1664\n",
      "     NetBIOS   0.732852  0.487103  0.585225      1667\n",
      "     Portmap   0.620220  0.846939  0.716062      1666\n",
      "        SNMP   0.711567  0.852430  0.775655      1667\n",
      "        SSDP   0.646372  0.764706  0.700577      1666\n",
      "         Syn   0.988458  0.565426  0.719359      1666\n",
      "        TFTP   0.998792  0.993393  0.996086      1665\n",
      "         UDP   0.690672  0.604442  0.644686      1666\n",
      "     UDP-lag   0.659253  0.889022  0.757088      1667\n",
      "\n",
      "    accuracy                       0.765791     19995\n",
      "   macro avg   0.724125  0.706974  0.703478     19995\n",
      "weighted avg   0.784346  0.765791  0.761991     19995\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(list(y_mult), y_pred2, digits=6, target_names=multiclass_labels_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Calculation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN   0.999650  0.999900  0.999775     19999\n",
      "         DNS   0.791189  0.539016  0.641200      1666\n",
      "        LDAP   0.623523  0.696461  0.657977      1667\n",
      "       MSSQL   0.954327  0.952609  0.953467      1667\n",
      "         NTP   0.996403  0.997001  0.996702      1667\n",
      "     NetBIOS   0.732852  0.487103  0.585225      1667\n",
      "     Portmap   0.620220  0.846431  0.715880      1667\n",
      "        SNMP   0.711567  0.852430  0.775655      1667\n",
      "        SSDP   0.646372  0.764247  0.700385      1667\n",
      "         Syn   0.988458  0.565426  0.719359      1666\n",
      "        TFTP   0.998792  0.992797  0.995786      1666\n",
      "         UDP   0.690672  0.604442  0.644686      1666\n",
      "     UDP-lag   0.659253  0.889022  0.757088      1667\n",
      "\n",
      "    accuracy                       0.882747     39999\n",
      "   macro avg   0.801021  0.783606  0.780245     39999\n",
      "weighted avg   0.892049  0.882747  0.880861     39999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = list(X_rem[\"binary_pred\"].values.copy())\n",
    "y_pred_final.extend(y_pred2)\n",
    "\n",
    "y_true_final = list(X_rem[\" Label\"].values.copy())\n",
    "y_true_final.extend(list(y_mult))\n",
    "\n",
    "print(classification_report(y_true_final, y_pred_final, digits=6, target_names=multiclass_labels_add))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4593b52a31704b5155580280f0f05a500adb36bf97584c7e94e26dfe17ea16d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

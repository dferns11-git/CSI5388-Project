{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is our 2-stage testing script (binary and multiclass)\n",
    "\n",
    "Author: Wesley\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and get binary and multiclass y columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENIGN     50000\n",
      "LDAP       50000\n",
      "NetBIOS    50000\n",
      "MSSQL      50000\n",
      "Portmap    50000\n",
      "Syn        50000\n",
      "UDP        50000\n",
      "UDP-lag     1873\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "binary = pd.read_csv(\"testing_set.csv\")\n",
    "col = binary[\" Label\"].values\n",
    "col = [\"UDP-lag\" if x == \"UDPLag\" else x for x in col]\n",
    "binary[\" Label\"] = col.copy()\n",
    "\n",
    "binary.head()\n",
    "print(binary[\" Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get binary encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text labels from the encoding will be passed to classification report so we can interpret our results more easily.\n",
      "\n",
      "Binary Label Encodings (in order of digits 0 -> 1): \n",
      "['BENIGN', 'ATTACK']\n"
     ]
    }
   ],
   "source": [
    "y = binary[\" Label\"].copy()\n",
    "X = binary.drop([\" Label\"], axis=1)\n",
    "y_bin = [0 if x==\"BENIGN\" else 1 for x in y.values]\n",
    "\n",
    "print(\"The text labels from the encoding will be passed to classification report so we can interpret our results more easily.\\n\")\n",
    "binary_labels = [\"BENIGN\", \"ATTACK\"]\n",
    "\n",
    "print(\"Binary Label Encodings (in order of digits 0 -> 1): \")\n",
    "print(binary_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get multiclass encodings and transform the test set with them. Use dummy label for Portmap\n",
    "\n",
    "Necessary because LabelEncoder was used on the models that were trained..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiclass Label Encodings (in order of digits 0 -> n): \n",
      "['BENIGN', 'DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']\n"
     ]
    }
   ],
   "source": [
    "# Encode attack labels to int and save as array to be used later.\n",
    "le = LabelEncoder()\n",
    "\n",
    "enc_helper = pd.read_csv(\"binary.csv\")\n",
    "le.fit(enc_helper[\" Label\"].values)\n",
    "y_multi = le.transform(enc_helper[\" Label\"].values)\n",
    "\n",
    "multiclass_labels = []\n",
    "print(\"\\nMulticlass Label Encodings (in order of digits 0 -> n): \")\n",
    "for i in range(0, len(list(set(list(y_multi))))):\n",
    "    multiclass_labels.append(le.inverse_transform([i])[0])\n",
    "\n",
    "print(multiclass_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the right labels, build the label set.\n",
    "y_multi = y.values\n",
    "\n",
    "y_multi = [20 if x==\"Portmap\" else multiclass_labels.index(x) for x in y_multi]\n",
    "\n",
    "# Offset encoding so it corresponds to our original encoding (no benign column, which is now -1)\n",
    "y_multi = [x-1 for x in y_multi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Load a binary model\n",
    "stage_1 = pickle.load(open(\"rf_binary_test.pickle\", 'rb'))\n",
    "\n",
    "# Load a multiclass model\n",
    "stage_2 = keras.models.load_model('LSTM_big.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1 Prediction (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stage_1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN   0.497568  0.996400  0.663705     50000\n",
      "      ATTACK   0.999285  0.833350  0.908806    301873\n",
      "\n",
      "    accuracy                       0.856519    351873\n",
      "   macro avg   0.748427  0.914875  0.786255    351873\n",
      "weighted avg   0.927993  0.856519  0.873977    351873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_bin, y_pred, digits=6, target_names=binary_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housekeeping to prepare the dataset for 2nd stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\icarus\\AppData\\Local\\Temp\\ipykernel_38612\\3257394839.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_rem['binary_pred'] = X_rem['binary_pred'].replace([0], -1)\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframe out of binary predictions and multiclass labels that can be used to compare them later.\n",
    "X_agg = X.copy()\n",
    "X_agg[\"binary_pred\"] = y_pred.copy()\n",
    "X_agg[\" Labels\"] = y_multi.copy()\n",
    "\n",
    "# Slice out the portions that we've identified as benign and replace their label with that of the multiclass benign label for comparison later.\n",
    "X_rem = X_agg[X_agg[\"binary_pred\"] == 0]\n",
    "X_rem['binary_pred'] = X_rem['binary_pred'].replace([0], -1)\n",
    "\n",
    "# Slice out the portions we've labeled as attack for 2nd stage classification.\n",
    "X_mult = X_agg[X_agg[\"binary_pred\"] == 1]\n",
    "X_mult = X_mult.drop([\"binary_pred\"], axis = 1)\n",
    "y_mult = X_mult[\" Labels\"].copy()\n",
    "X_mult = X_mult.drop([\" Labels\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd stage prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7868/7868 [==============================] - 18s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Some reshaping is needed for the LSTM model to work\n",
    "scal = StandardScaler()\n",
    "X_tr = scal.fit_transform(X_mult)\n",
    "X_tr = np.reshape(X_tr, (X_mult.shape[0], 1, X_mult.shape[1]))\n",
    "\n",
    "y_pred2 = stage_2.predict(X_tr)\n",
    "y_pred2 = [np.argmax(x) for x in y_pred2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BENIGN', 'DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag', 'Portmap']\n"
     ]
    }
   ],
   "source": [
    "multiclass_labels.append(\"Portmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN   0.000000  0.000000  0.000000       180\n",
      "         DNS   0.000000  0.000000  0.000000         0\n",
      "        LDAP   0.937985  0.996819  0.966507     49981\n",
      "       MSSQL   0.965684  0.559753  0.708708     49972\n",
      "         NTP   0.000000  0.000000  0.000000         0\n",
      "     NetBIOS   0.498137  0.024068  0.045917     49984\n",
      "        SNMP   0.000000  0.000000  0.000000         0\n",
      "        SSDP   0.000000  0.000000  0.000000         0\n",
      "         Syn   0.034483  0.138889  0.055249        36\n",
      "        TFTP   0.000000  0.000000  0.000000         0\n",
      "         UDP   0.651672  0.266345  0.378140     49984\n",
      "     UDP-lag   0.028674  0.022612  0.025284      1769\n",
      "     Portmap   0.000000  0.000000  0.000000     49840\n",
      "\n",
      "    accuracy                       0.366858    251746\n",
      "   macro avg   0.239741  0.154499  0.167677    251746\n",
      "weighted avg   0.606415  0.366858  0.416949    251746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_mult, y_pred2, digits=6, target_names=multiclass_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Calculation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN   0.497568  0.996400  0.663705     50000\n",
      "         DNS   0.000000  0.000000  0.000000         0\n",
      "        LDAP   0.937985  0.996440  0.966329     50000\n",
      "       MSSQL   0.965684  0.559440  0.708457     50000\n",
      "         NTP   0.000000  0.000000  0.000000         0\n",
      "     NetBIOS   0.498137  0.024060  0.045903     50000\n",
      "        SNMP   0.000000  0.000000  0.000000         0\n",
      "        SSDP   0.000000  0.000000  0.000000         0\n",
      "         Syn   0.034483  0.000100  0.000199     50000\n",
      "        TFTP   0.000000  0.000000  0.000000         0\n",
      "         UDP   0.651672  0.266260  0.378054     50000\n",
      "     UDP-lag   0.028674  0.021356  0.024480      1873\n",
      "     Portmap   0.000000  0.000000  0.000000     50000\n",
      "\n",
      "    accuracy                       0.404052    351873\n",
      "   macro avg   0.278016  0.220312  0.214394    351873\n",
      "weighted avg   0.509644  0.404052  0.392693    351873\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = list(X_rem[\"binary_pred\"].values.copy())\n",
    "y_pred_final.extend(y_pred2)\n",
    "\n",
    "y_true_final = list(X_rem[\" Labels\"].values.copy())\n",
    "y_true_final.extend(y_mult.values)\n",
    "\n",
    "print(classification_report(y_true_final, y_pred_final, digits=6, target_names=multiclass_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4593b52a31704b5155580280f0f05a500adb36bf97584c7e94e26dfe17ea16d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

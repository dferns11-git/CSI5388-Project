{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This extracts data from the dataset files since they are too big to all fit in memory.\n",
    "\n",
    "Assumes the original dataset folders are located in the same directory in their original form.\n",
    "\n",
    "Author: Wesley\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd # get dask with: pip install \"dask[complete]\"\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the original dataset files are too big to be loaded into memory, and since the benign cases are spread out across all the parts, we extract what we need from all of them to prepare our extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes we've placed program in root of dataset folder, where both days are subdirectories.\n",
    "path1 = os.getcwd() + \"/01-12\"\n",
    "path2 = os.getcwd() + \"/03-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files in each directory.\n",
    "fileList = [path1 + '/' + f for f in listdir(path1) if isfile(join(path1, f))]\n",
    "fileList2 = [path2 + '/' + f for f in listdir(path2) if isfile(join(path2, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge(fileList):\n",
    "    for f in fileList:\n",
    "\n",
    "        # Bypass the one that's too big.\n",
    "        if 'TFTP.csv' in f:\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(f, dtype={'SimillarHTTP': 'object'})\n",
    "        # Remove socket information and timestamp.\n",
    "        drop_cols = ['Flow ID', ' Source IP', ' Source Port', ' Destination IP',' Destination Port', ' Timestamp']\n",
    "\n",
    "        df = df.drop(drop_cols, axis=1)\n",
    "\n",
    "\n",
    "        # remove infinity values\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "\n",
    "        # replace invalid SimilarHTTP values with NaN\n",
    "        for col in df.columns:\n",
    "            if col != \" Label\":\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        df = df.dropna(axis=0)\n",
    "\n",
    "        df = df.drop([\"Unnamed: 0\"], axis= 1)\n",
    "\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        # get file name from path (file.csv)\n",
    "        targetIndex = f.rfind(\"/\") + 1\n",
    "        fileName = f[targetIndex:len(f)]\n",
    "\n",
    "        path_name = f[0:targetIndex]\n",
    "\n",
    "        # get file name without .csv extension (file)\n",
    "        targetIndex = fileName.rfind(\".\")\n",
    "        fileString = fileName[0:targetIndex]\n",
    "\n",
    "        new_path = path_name + fileString + \"_cleaned.csv\"\n",
    "\n",
    "        df.to_csv(new_path, index=False)\n",
    "\n",
    "        print(df[\" Label\"].value_counts())\n",
    "        print(f\"Wrote {new_path}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrDoS_DNS    108065\n",
      "BENIGN         2924\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/DrDoS_DNS_cleaned.csv\n",
      "DrDoS_LDAP    28839\n",
      "BENIGN         1359\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/DrDoS_LDAP_cleaned.csv\n",
      "DrDoS_MSSQL    193584\n",
      "BENIGN           1810\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/DrDoS_MSSQL_cleaned.csv\n",
      "DrDoS_NetBIOS    17953\n",
      "BENIGN            1568\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/DrDoS_NetBIOS_cleaned.csv\n",
      "DrDoS_NTP    1112274\n",
      "BENIGN         12724\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/DrDoS_NTP_cleaned.csv\n",
      "DrDoS_SNMP    111993\n",
      "BENIGN          1253\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/DrDoS_SNMP_cleaned.csv\n",
      "DrDoS_SSDP    890395\n",
      "BENIGN           711\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/DrDoS_SSDP_cleaned.csv\n",
      "DrDoS_UDP    1074526\n",
      "BENIGN          1967\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/DrDoS_UDP_cleaned.csv\n",
      "Syn       155495\n",
      "BENIGN       355\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/Syn_cleaned.csv\n",
      "UDP-lag    89032\n",
      "BENIGN      3393\n",
      "WebDDoS      297\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/01-12/UDPLag_cleaned.csv\n",
      "LDAP       16466\n",
      "BENIGN      4472\n",
      "NetBIOS     1420\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/03-11/LDAP_cleaned.csv\n",
      "MSSQL     253445\n",
      "BENIGN      2526\n",
      "LDAP         576\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/03-11/MSSQL_cleaned.csv\n",
      "NetBIOS    9890\n",
      "BENIGN     1200\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/03-11/NetBIOS_cleaned.csv\n",
      "BENIGN     4251\n",
      "Portmap    1598\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/03-11/Portmap_cleaned.csv\n",
      "Syn       452939\n",
      "BENIGN     26046\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/03-11/Syn_cleaned.csv\n",
      "UDP       1288589\n",
      "MSSQL        5024\n",
      "BENIGN       2763\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/03-11/UDP_cleaned.csv\n",
      "Syn       79058\n",
      "UDP       56476\n",
      "BENIGN     3638\n",
      "UDPLag      455\n",
      "Name:  Label, dtype: int64\n",
      "Wrote c:\\Users\\icarus\\Documents\\school\\Fall 2022\\CSI 5388\\dataset/03-11/UDPLag_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "purge(fileList)\n",
    "purge(fileList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge_chunk(df):\n",
    "\n",
    "    drop_cols = ['Flow ID', ' Source IP', ' Source Port', ' Destination IP',' Destination Port', ' Timestamp']\n",
    "\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "\n",
    "\n",
    "    # remove infinity values\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "\n",
    "    # replace invalid SimilarHTTP values with NaN\n",
    "    for col in df.columns:\n",
    "        if col != \" Label\":\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    df = df.dropna(axis=0)\n",
    "\n",
    "    df = df.drop([\"Unnamed: 0\"], axis= 1)\n",
    "\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10 ** 6\n",
    "chunklist = []\n",
    "with pd.read_csv(os.getcwd() + \"/01-12/TFTP.csv\", chunksize=chunksize, dtype={'SimillarHTTP': 'object'}) as reader:\n",
    "    for chunk in reader:\n",
    "        chunklist.append(purge_chunk(chunk))\n",
    "\n",
    "tf = pd.concat(chunklist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tf.drop_duplicates()\n",
    "tf.to_csv(os.getcwd() + \"/01-12/TFTP_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes we've placed program in root of dataset folder, where both days are subdirectories.\n",
    "path1 = os.getcwd() + \"/01-12-c\"\n",
    "path2 = os.getcwd() + \"/03-11-c\"\n",
    "# Get list of files in each directory.\n",
    "fileList = [path1 + '/' + f for f in listdir(path1) if isfile(join(path1, f))]\n",
    "fileList2 = [path2 + '/' + f for f in listdir(path2) if isfile(join(path2, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function extracts an equal amount of benign and attack data for each day and forms the train/test sets.\n",
    "\n",
    "Needs Dask due to how large many of the datasets are.\n",
    "\"\"\"\n",
    "def extract(fileList):\n",
    "\n",
    "    print(\"Beginning extraction of benign data...\")\n",
    "    # First pass aggregates BENIGN data.\n",
    "    i = 0\n",
    "    outFrame = None\n",
    "    for f in fileList:\n",
    "        df = dd.read_csv(f, dtype={'SimillarHTTP': 'object'})\n",
    "        lind = f.rfind('/')\n",
    "        slind = f.rfind('/', 0,lind-1)\n",
    "        print(f[slind:])\n",
    "\n",
    "        # Pull benign samples out and get their quantity.\n",
    "        ben_df = df[df[' Label'] == 'BENIGN']\n",
    "\n",
    "        if i == 0:\n",
    "            outFrame = ben_df\n",
    "            i += 1\n",
    "\n",
    "        else:    \n",
    "            outFrame = dd.concat([outFrame, ben_df])\n",
    "\n",
    "    # Get the total count of BENIGN samples that we've aggregated.\n",
    "    shben = outFrame.shape\n",
    "    ben_num = shben[0].compute()\n",
    "    print(f\"Number of Benign samples aggregated: {ben_num}\")\n",
    "\n",
    "    # Get an upper bound on the number of attack samples to extract. Goal is to get enough to be able to make them all equal after cleaning.\n",
    "    ben_num = 600000\n",
    "    \n",
    "    print(\"Beginning extraction of attack data...\")\n",
    "\n",
    "    # Second pass pulls out attack data equal in quantity to the count of benign data that we've gathered.\n",
    "    for f in fileList:\n",
    "        df = dd.read_csv(f, dtype={'SimillarHTTP': 'object'})\n",
    "        lind = f.rfind('/')\n",
    "        slind = f.rfind('/', 0,lind-1)\n",
    "        print(f[slind:])\n",
    "  \n",
    "        # Get list of label categories\n",
    "        cats = list(set(list(df[' Label'])))\n",
    "\n",
    "        # Go through non-benign categories and add a subsample equal in quantity to the number of benign samples.\n",
    "        for cat in cats:\n",
    "\n",
    "            if cat != \"BENIGN\":\n",
    "\n",
    "                print(f\"Appending data for {cat}...\")\n",
    "\n",
    "                # Find our how many samples we have\n",
    "                cat_df = df[df[' Label'] == cat]\n",
    "                shcat = cat_df.shape\n",
    "                cat_num = shcat[0].compute()\n",
    "\n",
    "                # Get a sample if there is equal/more attack data, otherwise add everything.\n",
    "                # dask only does approximate sampling, so we'll have to do some post-processing to make the numbers exactly equal.\n",
    "                if cat_num > ben_num:\n",
    "                    ret_df = cat_df.sample(frac = ben_num / cat_num)\n",
    "\n",
    "                else:\n",
    "                    ret_df = cat_df\n",
    "\n",
    "                outFrame = dd.concat([outFrame, ret_df])\n",
    "\n",
    "    # Return our aggregated DataFrame\n",
    "    print(f\"Aggregated df stats: {outFrame[' Label'].value_counts().compute()}\\n\")\n",
    "    print(\"Extraction completed.\")\n",
    "    return outFrame\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning extraction of benign data...\n",
      "/01-12-c/DrDoS_DNS_cleaned.csv\n",
      "/01-12-c/DrDoS_LDAP_cleaned.csv\n",
      "/01-12-c/DrDoS_MSSQL_cleaned.csv\n",
      "/01-12-c/DrDoS_NetBIOS_cleaned.csv\n",
      "/01-12-c/DrDoS_NTP_cleaned.csv\n",
      "/01-12-c/DrDoS_SNMP_cleaned.csv\n",
      "/01-12-c/DrDoS_SSDP_cleaned.csv\n",
      "/01-12-c/DrDoS_UDP_cleaned.csv\n",
      "/01-12-c/Syn_cleaned.csv\n",
      "/01-12-c/TFTP_cleaned.csv\n",
      "/01-12-c/UDPLag_cleaned.csv\n",
      "Number of Benign samples aggregated: 50111\n",
      "Beginning extraction of attack data...\n",
      "/01-12-c/DrDoS_DNS_cleaned.csv\n",
      "Appending data for DrDoS_DNS...\n",
      "/01-12-c/DrDoS_LDAP_cleaned.csv\n",
      "Appending data for DrDoS_LDAP...\n",
      "/01-12-c/DrDoS_MSSQL_cleaned.csv\n",
      "Appending data for DrDoS_MSSQL...\n",
      "/01-12-c/DrDoS_NetBIOS_cleaned.csv\n",
      "Appending data for DrDoS_NetBIOS...\n",
      "/01-12-c/DrDoS_NTP_cleaned.csv\n",
      "Appending data for DrDoS_NTP...\n",
      "/01-12-c/DrDoS_SNMP_cleaned.csv\n",
      "Appending data for DrDoS_SNMP...\n",
      "/01-12-c/DrDoS_SSDP_cleaned.csv\n",
      "Appending data for DrDoS_SSDP...\n",
      "/01-12-c/DrDoS_UDP_cleaned.csv\n",
      "Appending data for DrDoS_UDP...\n",
      "/01-12-c/Syn_cleaned.csv\n",
      "Appending data for Syn...\n",
      "/01-12-c/TFTP_cleaned.csv\n",
      "Appending data for TFTP...\n",
      "/01-12-c/UDPLag_cleaned.csv\n",
      "Appending data for UDP-lag...\n",
      "Appending data for WebDDoS...\n",
      "Aggregated df stats: DrDoS_UDP        600001\n",
      "DrDoS_SSDP       600000\n",
      "TFTP             600000\n",
      "DrDoS_NTP        599999\n",
      "DrDoS_MSSQL      193584\n",
      "Syn              155495\n",
      "DrDoS_SNMP       111993\n",
      "DrDoS_DNS        108065\n",
      "UDP-lag           89032\n",
      "BENIGN            50111\n",
      "DrDoS_LDAP        28839\n",
      "DrDoS_NetBIOS     17953\n",
      "WebDDoS             297\n",
      "Name:  Label, dtype: int64\n",
      "\n",
      "Extraction completed.\n",
      "Beginning extraction of benign data...\n",
      "/03-11-c/LDAP_cleaned.csv\n",
      "/03-11-c/MSSQL_cleaned.csv\n",
      "/03-11-c/NetBIOS_cleaned.csv\n",
      "/03-11-c/Portmap_cleaned.csv\n",
      "/03-11-c/Syn_cleaned.csv\n",
      "/03-11-c/UDPLag_cleaned.csv\n",
      "/03-11-c/UDP_cleaned.csv\n",
      "Number of Benign samples aggregated: 44896\n",
      "Beginning extraction of attack data...\n",
      "/03-11-c/LDAP_cleaned.csv\n",
      "Appending data for NetBIOS...\n",
      "Appending data for LDAP...\n",
      "/03-11-c/MSSQL_cleaned.csv\n",
      "Appending data for LDAP...\n",
      "Appending data for MSSQL...\n",
      "/03-11-c/NetBIOS_cleaned.csv\n",
      "Appending data for NetBIOS...\n",
      "/03-11-c/Portmap_cleaned.csv\n",
      "Appending data for Portmap...\n",
      "/03-11-c/Syn_cleaned.csv\n",
      "Appending data for Syn...\n",
      "/03-11-c/UDPLag_cleaned.csv\n",
      "Appending data for UDP...\n",
      "Appending data for Syn...\n",
      "Appending data for UDPLag...\n",
      "/03-11-c/UDP_cleaned.csv\n",
      "Appending data for UDP...\n",
      "Appending data for MSSQL...\n",
      "Aggregated df stats: UDP        656477\n",
      "Syn        531997\n",
      "MSSQL      258469\n",
      "BENIGN      44896\n",
      "LDAP        17042\n",
      "NetBIOS     11310\n",
      "Portmap      1598\n",
      "UDPLag        455\n",
      "Name:  Label, dtype: int64\n",
      "\n",
      "Extraction completed.\n"
     ]
    }
   ],
   "source": [
    "train = extract(fileList)\n",
    "test = extract(fileList2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save extracts, then reload them to finish processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\icarus\\\\Documents\\\\school\\\\Fall 2022\\\\CSI 5388\\\\dataset\\\\day1_v5.csv']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.to_csv(df = train, filename = \"day1_v5.csv\", single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\icarus\\\\Documents\\\\school\\\\Fall 2022\\\\CSI 5388\\\\dataset\\\\day2_v5.csv']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.to_csv(df = test, filename = \"day2_v5.csv\", single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"day1_v5.csv\")\n",
    "df2 = pd.read_csv(\"day2_v5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>SimillarHTTP</th>\n",
       "      <th>Inbound</th>\n",
       "      <th>Label</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>40335006</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>90287.0</td>\n",
       "      <td>90185.0</td>\n",
       "      <td>9.993447e+06</td>\n",
       "      <td>40495.753715</td>\n",
       "      <td>10018634.0</td>\n",
       "      <td>9933709.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>113244633</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2978061.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.188876e+06</td>\n",
       "      <td>809901.667647</td>\n",
       "      <td>9882838.0</td>\n",
       "      <td>6781893.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>95628949</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>...</td>\n",
       "      <td>15367.0</td>\n",
       "      <td>14798.0</td>\n",
       "      <td>1.001418e+07</td>\n",
       "      <td>5184.077926</td>\n",
       "      <td>10016037.0</td>\n",
       "      <td>10000366.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>95613243</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>...</td>\n",
       "      <td>26534.0</td>\n",
       "      <td>26473.0</td>\n",
       "      <td>1.000431e+07</td>\n",
       "      <td>21.430119</td>\n",
       "      <td>10004365.0</td>\n",
       "      <td>10004289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>95597710</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>...</td>\n",
       "      <td>26522.0</td>\n",
       "      <td>26437.0</td>\n",
       "      <td>1.000608e+07</td>\n",
       "      <td>5194.514136</td>\n",
       "      <td>10019931.0</td>\n",
       "      <td>10004309.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1   Protocol   Flow Duration   Total Fwd Packets  \\\n",
       "0            30          6        40335006                   9   \n",
       "1            52          0       113244633                  56   \n",
       "2            92          6        95628949                  21   \n",
       "3            93          6        95613243                  21   \n",
       "4            94          6        95597710                  21   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                       10                          8.0   \n",
       "1                        0                          0.0   \n",
       "2                       20                         20.0   \n",
       "3                       20                         20.0   \n",
       "4                       20                         20.0   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                          62.0                     1.0   \n",
       "1                           0.0                     0.0   \n",
       "2                           0.0                     1.0   \n",
       "3                           0.0                     1.0   \n",
       "4                           0.0                     1.0   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean  ...   Active Max  \\\n",
       "0                     0.0                 0.888889  ...      90287.0   \n",
       "1                     0.0                 0.000000  ...    2978061.0   \n",
       "2                     0.0                 0.952381  ...      15367.0   \n",
       "3                     0.0                 0.952381  ...      26534.0   \n",
       "4                     0.0                 0.952381  ...      26522.0   \n",
       "\n",
       "    Active Min     Idle Mean       Idle Std    Idle Max    Idle Min  \\\n",
       "0      90185.0  9.993447e+06   40495.753715  10018634.0   9933709.0   \n",
       "1          4.0  9.188876e+06  809901.667647   9882838.0   6781893.0   \n",
       "2      14798.0  1.001418e+07    5184.077926  10016037.0  10000366.0   \n",
       "3      26473.0  1.000431e+07      21.430119  10004365.0  10004289.0   \n",
       "4      26437.0  1.000608e+07    5194.514136  10019931.0  10004309.0   \n",
       "\n",
       "   SimillarHTTP   Inbound   Label  Unnamed: 0  \n",
       "0           0.0         0  BENIGN         NaN  \n",
       "1           0.0         0  BENIGN         NaN  \n",
       "2           0.0         0  BENIGN         NaN  \n",
       "3           0.0         0  BENIGN         NaN  \n",
       "4           0.0         0  BENIGN         NaN  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>SimillarHTTP</th>\n",
       "      <th>Inbound</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>8001234</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8001232.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8001232.0</td>\n",
       "      <td>8001232.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154</td>\n",
       "      <td>6</td>\n",
       "      <td>112729696</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>368.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>82.024387</td>\n",
       "      <td>62271.0</td>\n",
       "      <td>62155.0</td>\n",
       "      <td>56301460.5</td>\n",
       "      <td>3.535899e+06</td>\n",
       "      <td>58801719.0</td>\n",
       "      <td>53801202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Protocol   Flow Duration   Total Fwd Packets  \\\n",
       "0          35          6               1                   2   \n",
       "1          60          6              47                   2   \n",
       "2          61          6               1                   2   \n",
       "3         119          6         8001234                   4   \n",
       "4         154          6       112729696                  13   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                        0                         12.0   \n",
       "1                        0                         12.0   \n",
       "2                        0                         12.0   \n",
       "3                        0                          0.0   \n",
       "4                        6                        368.0   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                           0.0                     6.0   \n",
       "1                           0.0                     6.0   \n",
       "2                           0.0                     6.0   \n",
       "3                           0.0                     0.0   \n",
       "4                         196.0                    46.0   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean  ...   Active Std  \\\n",
       "0                     6.0                 6.000000  ...     0.000000   \n",
       "1                     6.0                 6.000000  ...     0.000000   \n",
       "2                     6.0                 6.000000  ...     0.000000   \n",
       "3                     0.0                 0.000000  ...     0.000000   \n",
       "4                     6.0                28.307692  ...    82.024387   \n",
       "\n",
       "    Active Max   Active Min   Idle Mean      Idle Std    Idle Max    Idle Min  \\\n",
       "0          0.0          0.0         0.0  0.000000e+00         0.0         0.0   \n",
       "1          0.0          0.0         0.0  0.000000e+00         0.0         0.0   \n",
       "2          0.0          0.0         0.0  0.000000e+00         0.0         0.0   \n",
       "3          1.0          1.0   8001232.0  0.000000e+00   8001232.0   8001232.0   \n",
       "4      62271.0      62155.0  56301460.5  3.535899e+06  58801719.0  53801202.0   \n",
       "\n",
       "   SimillarHTTP   Inbound   Label  \n",
       "0           0.0         0  BENIGN  \n",
       "1           0.0         1  BENIGN  \n",
       "2           0.0         0  BENIGN  \n",
       "3           0.0         1  BENIGN  \n",
       "4           0.0         0  BENIGN  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrDoS_UDP        600001\n",
      "DrDoS_SSDP       600000\n",
      "TFTP             600000\n",
      "DrDoS_NTP        599999\n",
      "DrDoS_MSSQL      193584\n",
      "Syn              155495\n",
      "DrDoS_SNMP       111993\n",
      "DrDoS_DNS        108065\n",
      "UDP-lag           89032\n",
      "BENIGN            50111\n",
      "DrDoS_LDAP        28839\n",
      "DrDoS_NetBIOS     17953\n",
      "WebDDoS             297\n",
      "Name:  Label, dtype: int64\n",
      "UDP        656477\n",
      "Syn        531997\n",
      "MSSQL      258469\n",
      "BENIGN      44896\n",
      "LDAP        17042\n",
      "NetBIOS     11310\n",
      "Portmap      1598\n",
      "UDPLag        455\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1[\" Label\"].value_counts())\n",
    "print(df2[\" Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now balance the samples and create our binary and multiclass datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BENIGN' 'DNS' 'LDAP' 'MSSQL' 'NetBIOS' 'NTP' 'SNMP' 'SSDP' 'UDP' 'Syn'\n",
      " 'TFTP' 'UDP-lag' 'WebDDoS']\n",
      "['BENIGN' 'NetBIOS' 'LDAP' 'MSSQL' 'Portmap' 'Syn' 'UDP' 'UDP-lag']\n"
     ]
    }
   ],
   "source": [
    "# get list of labels so we can pull an equal number of samples from each. Also standardize label names.\n",
    "df1[\" Label\"] = df1[\" Label\"].apply(lambda x: x.replace(\"DrDoS_\", \"\"))\n",
    "df2[\" Label\"] = df2[\" Label\"].apply(lambda x: x.replace(\"UDPLag\", \"UDP-lag\"))\n",
    "\n",
    "cols1 = df1[\" Label\"].unique()\n",
    "print(df1[\" Label\"].unique())\n",
    "cols2 = df2[\" Label\"].unique()\n",
    "print(df2[\" Label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop([\"Unnamed: 0.1\"], axis= 1)\n",
    "df2 = df2.drop([\"Unnamed: 0\"], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop_duplicates()\n",
    "df2 = df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSDP       600000\n",
      "UDP        600000\n",
      "TFTP       600000\n",
      "NTP        599998\n",
      "MSSQL      193584\n",
      "Syn        155495\n",
      "SNMP       111988\n",
      "DNS        108065\n",
      "UDP-lag     89032\n",
      "BENIGN      49302\n",
      "LDAP        28839\n",
      "NetBIOS     17953\n",
      "WebDDoS       297\n",
      "Name:  Label, dtype: int64\n",
      "UDP        647996\n",
      "Syn        525832\n",
      "MSSQL      254092\n",
      "BENIGN      43575\n",
      "LDAP        16568\n",
      "NetBIOS     10231\n",
      "Portmap      1598\n",
      "UDP-lag       455\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1[\" Label\"].value_counts())\n",
    "print(df2[\" Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UDP        1247996\n",
      "Syn         681327\n",
      "SSDP        600000\n",
      "TFTP        600000\n",
      "NTP         599998\n",
      "MSSQL       447676\n",
      "SNMP        111988\n",
      "DNS         108065\n",
      "BENIGN       92877\n",
      "UDP-lag      89487\n",
      "LDAP         45407\n",
      "NetBIOS      28184\n",
      "Portmap       1598\n",
      "WebDDoS        297\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merge_df[\" Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UDP        1200195\n",
      "Syn         681311\n",
      "SSDP        600000\n",
      "TFTP        600000\n",
      "NTP         599998\n",
      "MSSQL       349292\n",
      "SNMP        111988\n",
      "DNS         108065\n",
      "BENIGN       92738\n",
      "UDP-lag      89411\n",
      "LDAP         38114\n",
      "NetBIOS      25572\n",
      "Portmap       1598\n",
      "WebDDoS        297\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merge_df = merge_df.drop_duplicates()\n",
    "print(merge_df[\" Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNS        15457\n",
      "LDAP       15457\n",
      "MSSQL      15457\n",
      "NetBIOS    15457\n",
      "NTP        15457\n",
      "SNMP       15457\n",
      "SSDP       15457\n",
      "UDP        15457\n",
      "Syn        15457\n",
      "TFTP       15457\n",
      "UDP-lag    15457\n",
      "Portmap    15457\n",
      "Name:  Label, dtype: int64\n",
      "BENIGN     92738\n",
      "DNS         7729\n",
      "LDAP        7729\n",
      "MSSQL       7729\n",
      "NetBIOS     7729\n",
      "NTP         7729\n",
      "SNMP        7729\n",
      "SSDP        7729\n",
      "UDP         7729\n",
      "Syn         7729\n",
      "TFTP        7729\n",
      "UDP-lag     7729\n",
      "Portmap     7729\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assemble equal number of samples. Will be restructured in multiclass and binary datasets.\n",
    "outMult = None\n",
    "outBin = None\n",
    "ben = None\n",
    "for val in merge_df[\" Label\"].unique():\n",
    "\n",
    "    # too small, so we drop it\n",
    "    if val == 'WebDDoS':\n",
    "        continue\n",
    "\n",
    "    # Retain benign data separtely\n",
    "    elif val == \"BENIGN\":\n",
    "        ben = merge_df[merge_df[\" Label\"] == val].copy()\n",
    "        continue\n",
    "\n",
    "    # We have to pad Portmap since it's too small.\n",
    "    elif val == \"Portmap\":\n",
    "        # 1598\n",
    "        slice = merge_df[merge_df[\" Label\"] == val].copy()\n",
    "\n",
    "        # 3196\n",
    "        slice2 = pd.concat([slice, slice])\n",
    "\n",
    "        # 6392\n",
    "        slice3 = pd.concat([slice2, slice2])\n",
    "\n",
    "        # 25568\n",
    "        slice4 = pd.concat([slice3, slice3,slice3,slice3])\n",
    "\n",
    "        # Now we can get enough, lol.\n",
    "        slice = slice4.sample(n=23186,random_state=42) # Ensure equal sample number\n",
    "\n",
    "\n",
    "    else:\n",
    "        slice = merge_df[merge_df[\" Label\"] == val].copy()\n",
    "        slice = slice.sample(n=23186,random_state=42) # Ensure equal sample number\n",
    "\n",
    "    slice_bin = slice.iloc[:7729,:]\n",
    "    slice_mult = slice.iloc[7729:,:]\n",
    "    # add to output\n",
    "    if outMult is None:\n",
    "        outMult = slice_mult\n",
    "    else:\n",
    "        outMult = pd.concat([outMult, slice_mult])\n",
    "\n",
    "    if outBin is None:\n",
    "        outBin = slice_bin\n",
    "    else:\n",
    "        outBin = pd.concat([outBin, slice_bin])\n",
    "\n",
    "outBin = pd.concat([outBin, ben])\n",
    "print(outMult[\" Label\"].value_counts())\n",
    "print(outBin[\" Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outBin = outBin.drop(['Unnamed: 0'], axis=1)\n",
    "outMult = outMult.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary dataset will be binarized later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "binary_y = outBin[\" Label\"].copy()\n",
    "binary_x = outBin.drop([\" Label\"], axis=1)\n",
    "\n",
    "multiclass_y = outMult[\" Label\"].copy()\n",
    "multiclass_x = outMult.drop([\" Label\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(binary_x, binary_y, test_size=0.20, random_state=42, stratify = binary_y)\n",
    "binary_train = X_train\n",
    "binary_train[\" Label\"] = y_train.values\n",
    "binary_test = X_test\n",
    "binary_test[\" Label\"] = y_test.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(multiclass_x, multiclass_y, test_size=0.20, random_state=42, stratify = multiclass_y)\n",
    "multiclass_train = X_train\n",
    "multiclass_train[\" Label\"] = y_train.values\n",
    "multiclass_test = X_test\n",
    "multiclass_test[\" Label\"] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENIGN     74190\n",
      "TFTP        6184\n",
      "UDP         6184\n",
      "NetBIOS     6183\n",
      "SSDP        6183\n",
      "SNMP        6183\n",
      "NTP         6183\n",
      "Portmap     6183\n",
      "DNS         6183\n",
      "LDAP        6183\n",
      "MSSQL       6183\n",
      "UDP-lag     6183\n",
      "Syn         6183\n",
      "Name:  Label, dtype: int64\n",
      "BENIGN     18548\n",
      "UDP-lag     1546\n",
      "MSSQL       1546\n",
      "LDAP        1546\n",
      "Syn         1546\n",
      "Portmap     1546\n",
      "NTP         1546\n",
      "SSDP        1546\n",
      "DNS         1546\n",
      "SNMP        1546\n",
      "NetBIOS     1546\n",
      "TFTP        1545\n",
      "UDP         1545\n",
      "Name:  Label, dtype: int64\n",
      "TFTP       12366\n",
      "MSSQL      12366\n",
      "DNS        12366\n",
      "LDAP       12366\n",
      "Syn        12366\n",
      "Portmap    12366\n",
      "UDP        12366\n",
      "NTP        12365\n",
      "UDP-lag    12365\n",
      "SSDP       12365\n",
      "NetBIOS    12365\n",
      "SNMP       12365\n",
      "Name:  Label, dtype: int64\n",
      "UDP-lag    3092\n",
      "SSDP       3092\n",
      "SNMP       3092\n",
      "NTP        3092\n",
      "NetBIOS    3092\n",
      "Portmap    3091\n",
      "TFTP       3091\n",
      "DNS        3091\n",
      "Syn        3091\n",
      "LDAP       3091\n",
      "MSSQL      3091\n",
      "UDP        3091\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(binary_train[\" Label\"].value_counts())\n",
    "print(binary_test[\" Label\"].value_counts())\n",
    "print(multiclass_train[\" Label\"].value_counts())\n",
    "print(multiclass_test[\" Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train.to_csv(\"binary_train.csv\", index=False)\n",
    "binary_test.to_csv(\"binary_test.csv\", index=False)\n",
    "\n",
    "multiclass_train.to_csv(\"multiclass_train.csv\", index=False)\n",
    "multiclass_test.to_csv(\"multiclass_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4593b52a31704b5155580280f0f05a500adb36bf97584c7e94e26dfe17ea16d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

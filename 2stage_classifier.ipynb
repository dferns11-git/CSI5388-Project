{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is our 2-stage testing script (binary and multiclass)\n",
    "\n",
    "Author: Wesley\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a custom transformer that allows us to reduce the feature sets for each classifier appropriately.\n",
    "\n",
    "Necessary since we're making them all part of a StackingClassifier and each one uses a different feature set.\n",
    "\"\"\"\n",
    "class FeatureReducer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_list=None):\n",
    "        self.feature_list = feature_list\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if self.feature_list is None:\n",
    "            return X\n",
    "        \n",
    "        else:\n",
    "            return X.loc[:, self.feature_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and get binary and multiclass y columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENIGN     74190\n",
      "TFTP        6184\n",
      "UDP         6184\n",
      "NetBIOS     6183\n",
      "SSDP        6183\n",
      "SNMP        6183\n",
      "NTP         6183\n",
      "Portmap     6183\n",
      "DNS         6183\n",
      "LDAP        6183\n",
      "MSSQL       6183\n",
      "UDP-lag     6183\n",
      "Syn         6183\n",
      "Name:  Label, dtype: int64\n",
      "BENIGN     18548\n",
      "UDP-lag     1546\n",
      "MSSQL       1546\n",
      "LDAP        1546\n",
      "Syn         1546\n",
      "Portmap     1546\n",
      "NTP         1546\n",
      "SSDP        1546\n",
      "DNS         1546\n",
      "SNMP        1546\n",
      "NetBIOS     1546\n",
      "TFTP        1545\n",
      "UDP         1545\n",
      "Name:  Label, dtype: int64\n",
      "TFTP       12366\n",
      "MSSQL      12366\n",
      "DNS        12366\n",
      "LDAP       12366\n",
      "Syn        12366\n",
      "Portmap    12366\n",
      "UDP        12366\n",
      "NTP        12365\n",
      "UDP-lag    12365\n",
      "SSDP       12365\n",
      "NetBIOS    12365\n",
      "SNMP       12365\n",
      "Name:  Label, dtype: int64\n",
      "UDP-lag    3092\n",
      "SSDP       3092\n",
      "SNMP       3092\n",
      "NTP        3092\n",
      "NetBIOS    3092\n",
      "Portmap    3091\n",
      "TFTP       3091\n",
      "DNS        3091\n",
      "Syn        3091\n",
      "LDAP       3091\n",
      "MSSQL      3091\n",
      "UDP        3091\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "binary_train = pd.read_csv(\"binary_train.csv\")\n",
    "binary_test = pd.read_csv(\"binary_test.csv\")\n",
    "\n",
    "multiclass_train = pd.read_csv(\"multiclass_train.csv\")\n",
    "multiclass_test = pd.read_csv(\"multiclass_test.csv\")\n",
    "\n",
    "print(binary_train[\" Label\"].value_counts())\n",
    "print(binary_test[\" Label\"].value_counts())\n",
    "print(multiclass_train[\" Label\"].value_counts())\n",
    "print(multiclass_test[\" Label\"].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split and encode data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text labels from the encoding will be passed to classification report so we can interpret our results more easily.\n",
      "\n",
      "Binary Label Encodings (in order of digits 0 -> 1): \n",
      "['BENIGN', 'ATTACK']\n",
      "\n",
      "Multiclass Label Encodings (in order of digits 0 -> n): \n",
      "['DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']\n"
     ]
    }
   ],
   "source": [
    "bin_y_train = binary_train[\" Label\"].copy()\n",
    "bin_x_train = binary_train.drop([\" Label\"], axis=1)\n",
    "\n",
    "bin_y_test = binary_test[\" Label\"].copy()\n",
    "bin_x_test = binary_test.drop([\" Label\"], axis=1)\n",
    "\n",
    "bin_y_train = [0 if x==\"BENIGN\" else 1 for x in bin_y_train.values]\n",
    "bin_y_test = [0 if x==\"BENIGN\" else 1 for x in bin_y_test.values]\n",
    "\n",
    "print(\"The text labels from the encoding will be passed to classification report so we can interpret our results more easily.\\n\")\n",
    "binary_labels = [\"BENIGN\", \"ATTACK\"]\n",
    "\n",
    "print(\"Binary Label Encodings (in order of digits 0 -> 1): \")\n",
    "print(binary_labels)\n",
    "\n",
    "multi_y_train = multiclass_train[\" Label\"].copy()\n",
    "multi_x_train = multiclass_train.drop([\" Label\"], axis=1)\n",
    "\n",
    "multi_y_test = multiclass_test[\" Label\"].copy()\n",
    "multi_x_test = multiclass_test.drop([\" Label\"], axis=1)\n",
    "\n",
    "# Encode attack labels to int and save as array to be used later.\n",
    "le = LabelEncoder()\n",
    "\n",
    "multi_y_train = le.fit_transform(multi_y_train.values)\n",
    "multi_y_test = le.transform(multi_y_test.values)\n",
    "\n",
    "multiclass_labels = []\n",
    "print(\"\\nMulticlass Label Encodings (in order of digits 0 -> n): \")\n",
    "for i in range(0, len(list(set(list(multi_y_test))))):\n",
    "    multiclass_labels.append(le.inverse_transform([i])[0])\n",
    "\n",
    "print(multiclass_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = pickle.load(open(\"feature_sets.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a binary model\n",
    "stage_1 = make_pipeline(FeatureReducer(), RandomForestClassifier(random_state=42, criterion = 'entropy', max_depth = 100, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 7, n_estimators = 344))\n",
    "\n",
    "# Use the custom transformer to reduce the feature sets for each classifier appropriately.\n",
    "clf_knn = make_pipeline(FeatureReducer(feature_list = feature_sets[\"Multiclass\"][\"Mutual Information\"]), KNeighborsClassifier(algorithm = 'ball_tree', n_neighbors = 7, weights =  'distance'))\n",
    "clf_dt = make_pipeline(FeatureReducer(feature_list = feature_sets[\"Multiclass\"][\"RFE Sets\"][\"Decision Tree\"]), DecisionTreeClassifier(random_state = 42, criterion = 'entropy', max_depth = 18, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 10))\n",
    "clf_lr = make_pipeline(FeatureReducer(feature_list = feature_sets[\"Multiclass\"][\"RFE Sets\"][\"Logistic Regression\"]), StandardScaler(), LogisticRegression(C = 9972.476141278883, max_iter =  483, random_state=42))\n",
    "clf_rf = make_pipeline(FeatureReducer(), RandomForestClassifier(random_state=42, criterion = 'entropy', max_depth = 100, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 7, n_estimators = 344))\n",
    "\n",
    "# Load the estimators into a list.\n",
    "estimators = [(\"knn\",clf_knn),(\"dt\",clf_dt),(\"lr\",clf_lr),(\"rf\",clf_rf)]\n",
    "\n",
    "# Intialize the stacking classifier (finally)\n",
    "stage_2 = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1 Prediction (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scal = StandardScaler()\n",
    "#bin_x_train_reshaped = scal.fit_transform(bin_x_train)\n",
    "#bin_x_test_reshaped = scal.transform(bin_x_test)\n",
    "stage_1.fit(bin_x_train, bin_y_train)\n",
    "y_pred = stage_1.predict(bin_x_test)\n",
    "#y_pred = [1 if x>=0.5 else 0 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN   0.999030  0.999892  0.999461     18548\n",
      "      ATTACK   0.999892  0.999030  0.999461     18550\n",
      "\n",
      "    accuracy                       0.999461     37098\n",
      "   macro avg   0.999461  0.999461  0.999461     37098\n",
      "weighted avg   0.999461  0.999461  0.999461     37098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(bin_y_test, y_pred, digits=6, target_names=binary_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housekeeping to prepare the dataset for 2nd stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\icarus\\AppData\\Local\\Temp\\ipykernel_72828\\2310080828.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_rem['binary_pred'] = X_rem['binary_pred'].replace([0], -1)\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframe out of binary predictions and multiclass labels that can be used to compare them later.\n",
    "X_agg = bin_x_test.copy()\n",
    "X_agg[\"binary_pred\"] = y_pred.copy()\n",
    "X_agg[\" Label\"] = binary_test[\" Label\"].copy()\n",
    "#X_agg[\" Label\"] = le.transform(X_agg[\" Label\"].values)\n",
    "X_agg.loc[~X_agg[\" Label\"].isin(le.classes_),\" Label\"] = -1 \n",
    "X_agg.loc[X_agg[\" Label\"].isin(le.classes_),\" Label\"] = le.transform(X_agg[\" Label\"][X_agg[\" Label\"].isin(le.classes_)])\n",
    "\n",
    "# Slice out the portions that we've identified as benign and replace their label with that of the multiclass benign label for comparison later.\n",
    "X_rem = X_agg[X_agg[\"binary_pred\"] == 0]\n",
    "X_rem['binary_pred'] = X_rem['binary_pred'].replace([0], -1)\n",
    "\n",
    "# Slice out the portions we've labeled as attack for 2nd stage classification.\n",
    "X_mult = X_agg[X_agg[\"binary_pred\"] == 1]\n",
    "X_mult = X_mult.drop([\"binary_pred\"], axis = 1)\n",
    "y_mult = X_mult[\" Label\"].values.copy()\n",
    "\n",
    "X_mult = X_mult.drop([\" Label\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd stage prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Fit the stacking classifier\n",
    "stage_2.fit(multi_x_train, multi_y_train)\n",
    "\n",
    "y_pred2 = stage_2.predict(X_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([1169, 1854, 1597, 1535, 1506, 1641, 1570, 1842, 1502, 1540, 1331,\n",
      "       1447], dtype=int64))\n",
      "(array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([   2, 1542, 1543, 1545, 1544, 1545, 1546, 1542, 1546, 1545, 1545,\n",
      "       1545, 1544], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_pred2, return_counts=True))\n",
    "print(np.unique(list(y_mult), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']\n",
      "['BENIGN', 'DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']\n"
     ]
    }
   ],
   "source": [
    "print(multiclass_labels)\n",
    "multiclass_labels_add = [\"BENIGN\"]\n",
    "multiclass_labels_add.extend(multiclass_labels)\n",
    "print(multiclass_labels_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN   0.000000  0.000000  0.000000         2\n",
      "         DNS   0.773311  0.586252  0.666913      1542\n",
      "        LDAP   0.726537  0.872975  0.793053      1543\n",
      "       MSSQL   0.832185  0.860194  0.845958      1545\n",
      "         NTP   0.992834  0.987047  0.989932      1544\n",
      "     NetBIOS   0.839973  0.818770  0.829236      1545\n",
      "     Portmap   0.937233  0.994825  0.965171      1546\n",
      "        SNMP   0.819745  0.834630  0.827121      1542\n",
      "        SSDP   0.528230  0.629366  0.574380      1546\n",
      "         Syn   0.989348  0.961812  0.975386      1545\n",
      "        TFTP   1.000000  0.996764  0.998379      1545\n",
      "         UDP   0.528926  0.455663  0.489569      1545\n",
      "     UDP-lag   0.885280  0.829663  0.856570      1544\n",
      "\n",
      "    accuracy                       0.818927     18534\n",
      "   macro avg   0.757969  0.755997  0.754744     18534\n",
      "weighted avg   0.821041  0.818927  0.817560     18534\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(list(y_mult), y_pred2, digits=6, target_names=multiclass_labels_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Calculation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN   0.999030  0.999892  0.999461     18548\n",
      "         DNS   0.773311  0.584735  0.665930      1546\n",
      "        LDAP   0.726537  0.871281  0.792353      1546\n",
      "       MSSQL   0.832185  0.859638  0.845689      1546\n",
      "         NTP   0.992834  0.985770  0.989289      1546\n",
      "     NetBIOS   0.839973  0.818241  0.828965      1546\n",
      "     Portmap   0.937233  0.994825  0.965171      1546\n",
      "        SNMP   0.819745  0.832471  0.826059      1546\n",
      "        SSDP   0.528230  0.629366  0.574380      1546\n",
      "         Syn   0.989348  0.961190  0.975066      1546\n",
      "        TFTP   1.000000  0.996764  0.998379      1545\n",
      "         UDP   0.528926  0.455663  0.489569      1545\n",
      "     UDP-lag   0.885280  0.828590  0.855997      1546\n",
      "\n",
      "    accuracy                       0.909052     37098\n",
      "   macro avg   0.834818  0.832187  0.831254     37098\n",
      "weighted avg   0.910080  0.909052  0.908348     37098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = list(X_rem[\"binary_pred\"].values.copy())\n",
    "y_pred_final.extend(y_pred2)\n",
    "\n",
    "y_true_final = list(X_rem[\" Label\"].values.copy())\n",
    "y_true_final.extend(list(y_mult))\n",
    "\n",
    "print(classification_report(y_true_final, y_pred_final, digits=6, target_names=multiclass_labels_add))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4593b52a31704b5155580280f0f05a500adb36bf97584c7e94e26dfe17ea16d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

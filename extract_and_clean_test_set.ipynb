{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This extracts a test set. Different days for attack and benign than the training days.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd # get dask with: pip install \"dask[complete]\"\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the original dataset files are too big to be loaded into memory, and since the benign cases are spread out across all the parts, we extract what we need from all of them to prepare our extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes we've placed program in root of dataset folder, where both days are subdirectories.\n",
    "path1 = os.getcwd() + \"/01-12\"\n",
    "path2 = os.getcwd() + \"/03-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files in each directory.\n",
    "fileList = [path1 + '/' + f for f in listdir(path1) if isfile(join(path1, f))]\n",
    "fileList2 = [path2 + '/' + f for f in listdir(path2) if isfile(join(path2, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function extracts an equal amount of benign and attack data for each day and forms the train/test sets.\n",
    "\n",
    "Needs Dask due to how large many of the datasets are.\n",
    "\"\"\"\n",
    "def extract(fileList):\n",
    "\n",
    "    print(\"Beginning extraction of benign data...\")\n",
    "    # First pass aggregates BENIGN data.\n",
    "    i = 0\n",
    "    outFrame = None\n",
    "    for f in fileList:\n",
    "        df = dd.read_csv(f, dtype={'SimillarHTTP': 'object'})\n",
    "        lind = f.rfind('/')\n",
    "        slind = f.rfind('/', 0,lind-1)\n",
    "        print(f[slind:])\n",
    "        #print(f\"{df[' Label'].value_counts().compute()}\\n\")\n",
    "\n",
    "        # Pull benign samples out and get their quantity.\n",
    "        ben_df = df[df[' Label'] == 'BENIGN']\n",
    "\n",
    "        if i == 0:\n",
    "            outFrame = ben_df\n",
    "            i += 1\n",
    "\n",
    "        else:    \n",
    "            outFrame = dd.concat([outFrame, ben_df])\n",
    "\n",
    "        #print(f\"Aggregated df stats: {outFrame[' Label'].value_counts().compute()}\\n\")\n",
    "\n",
    "    # Get the total count of BENIGN samples that we've aggregated.\n",
    "    shben = outFrame.shape\n",
    "    ben_num = shben[0].compute()\n",
    "    print(f\"Number of Benign samples aggregated: {ben_num}\")\n",
    "\n",
    "    # Get an upper bound on the number of attack samples to extract. Goal is to get enough to be able to make them all equal after cleaning.\n",
    "    ben_num = 100000\n",
    "    \n",
    "    print(\"Beginning extraction of attack data...\")\n",
    "\n",
    "    # Second pass pulls out attack data equal in quantity to the count of benign data that we've gathered.\n",
    "    for f in fileList:\n",
    "        df = dd.read_csv(f, dtype={'SimillarHTTP': 'object'})\n",
    "        lind = f.rfind('/')\n",
    "        slind = f.rfind('/', 0,lind-1)\n",
    "        print(f[slind:])\n",
    "  \n",
    "        # Get list of label categories\n",
    "        cats = list(set(list(df[' Label'])))\n",
    "\n",
    "        # Go through non-benign categories and add a subsample equal in quantity to the number of benign samples.\n",
    "        for cat in cats:\n",
    "\n",
    "            if cat != \"BENIGN\":\n",
    "\n",
    "                print(f\"Appending data for {cat}...\")\n",
    "                # Find our how many samples we have\n",
    "                cat_df = df[df[' Label'] == cat]\n",
    "                shcat = cat_df.shape\n",
    "                cat_num = shcat[0].compute()\n",
    "\n",
    "                # Get a sample if there is equal/more attack data, otherwise add everything.\n",
    "                # dask only does approximate sampling, so we'll have to do some post-processing to make the numbers exactly equal.\n",
    "                if cat_num > ben_num:\n",
    "                    ret_df = cat_df.sample(frac = ben_num / cat_num)\n",
    "\n",
    "                else:\n",
    "                    ret_df = cat_df\n",
    "\n",
    "                outFrame = dd.concat([outFrame, ret_df])\n",
    "                #print(f\"Aggregated df stats: {outFrame[' Label'].value_counts().compute()}\\n\")\n",
    "\n",
    "    # Return our aggregated DataFrame\n",
    "    print(f\"Aggregated df stats: {outFrame[' Label'].value_counts().compute()}\\n\")\n",
    "    print(\"Extraction completed.\")\n",
    "    return outFrame\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning extraction of benign data...\n",
      "/01-12/DrDoS_DNS.csv\n",
      "/01-12/DrDoS_LDAP.csv\n",
      "/01-12/DrDoS_MSSQL.csv\n",
      "/01-12/DrDoS_NetBIOS.csv\n",
      "/01-12/DrDoS_NTP.csv\n",
      "/01-12/DrDoS_SNMP.csv\n",
      "/01-12/DrDoS_SSDP.csv\n",
      "/01-12/DrDoS_UDP.csv\n",
      "/01-12/Syn.csv\n",
      "/01-12/TFTP.csv\n",
      "/01-12/UDPLag.csv\n",
      "Number of Benign samples aggregated: 56863\n",
      "Beginning extraction of attack data...\n",
      "/01-12/DrDoS_DNS.csv\n",
      "Appending data for DrDoS_DNS...\n",
      "/01-12/DrDoS_LDAP.csv\n",
      "Appending data for DrDoS_LDAP...\n",
      "/01-12/DrDoS_MSSQL.csv\n",
      "Appending data for DrDoS_MSSQL...\n",
      "/01-12/DrDoS_NetBIOS.csv\n",
      "Appending data for DrDoS_NetBIOS...\n",
      "/01-12/DrDoS_NTP.csv\n",
      "Appending data for DrDoS_NTP...\n",
      "/01-12/DrDoS_SNMP.csv\n",
      "Appending data for DrDoS_SNMP...\n",
      "/01-12/DrDoS_SSDP.csv\n",
      "Appending data for DrDoS_SSDP...\n",
      "/01-12/DrDoS_UDP.csv\n",
      "Appending data for DrDoS_UDP...\n",
      "/01-12/Syn.csv\n",
      "Appending data for Syn...\n",
      "/01-12/TFTP.csv\n",
      "Appending data for TFTP...\n",
      "/01-12/UDPLag.csv\n",
      "Appending data for UDP-lag...\n",
      "Appending data for WebDDoS...\n",
      "Aggregated df stats: DrDoS_DNS        100001\n",
      "DrDoS_LDAP       100001\n",
      "DrDoS_SNMP       100001\n",
      "DrDoS_SSDP       100001\n",
      "DrDoS_MSSQL      100000\n",
      "DrDoS_NTP        100000\n",
      "DrDoS_NetBIOS    100000\n",
      "Syn              100000\n",
      "UDP-lag          100000\n",
      "DrDoS_UDP         99999\n",
      "TFTP              99999\n",
      "BENIGN            56863\n",
      "WebDDoS             439\n",
      "Name:  Label, dtype: int64\n",
      "\n",
      "Extraction completed.\n",
      "Beginning extraction of benign data...\n",
      "/03-11/LDAP.csv\n",
      "/03-11/MSSQL.csv\n",
      "/03-11/NetBIOS.csv\n",
      "/03-11/Portmap.csv\n",
      "/03-11/Syn.csv\n",
      "/03-11/UDP.csv\n",
      "/03-11/UDPLag.csv\n",
      "Number of Benign samples aggregated: 56965\n",
      "Beginning extraction of attack data...\n",
      "/03-11/LDAP.csv\n",
      "Appending data for LDAP...\n",
      "Appending data for NetBIOS...\n",
      "/03-11/MSSQL.csv\n",
      "Appending data for LDAP...\n",
      "Appending data for MSSQL...\n",
      "/03-11/NetBIOS.csv\n",
      "Appending data for NetBIOS...\n",
      "/03-11/Portmap.csv\n",
      "Appending data for Portmap...\n",
      "/03-11/Syn.csv\n",
      "Appending data for Syn...\n",
      "/03-11/UDP.csv\n",
      "Appending data for UDP...\n",
      "Appending data for MSSQL...\n",
      "/03-11/UDPLag.csv\n",
      "Appending data for Syn...\n",
      "Appending data for UDP...\n",
      "Appending data for UDPLag...\n",
      "Aggregated df stats: Syn        200005\n",
      "UDP        199999\n",
      "NetBIOS    199998\n",
      "MSSQL      124392\n",
      "LDAP       109932\n",
      "Portmap    100000\n",
      "BENIGN      56965\n",
      "UDPLag       1873\n",
      "Name:  Label, dtype: int64\n",
      "\n",
      "Extraction completed.\n"
     ]
    }
   ],
   "source": [
    "train = extract(fileList)\n",
    "test = extract(fileList2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save extracts, then reload them to finish processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\icarus\\\\Documents\\\\school\\\\Fall 2022\\\\CSI 5388\\\\dataset\\\\day1_v2.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.to_csv(df = train, filename = \"day1_v2.csv\", single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\icarus\\\\Documents\\\\school\\\\Fall 2022\\\\CSI 5388\\\\dataset\\\\day2_v2.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.to_csv(df = test, filename = \"day2_v2.csv\", single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\icarus\\AppData\\Local\\Temp\\ipykernel_10716\\2974041824.py:1: DtypeWarning: Columns (86) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(\"day1_v2.csv\")\n",
      "C:\\Users\\icarus\\AppData\\Local\\Temp\\ipykernel_10716\\2974041824.py:2: DtypeWarning: Columns (86) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(\"day2_v2.csv\")\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"day1_v2.csv\")\n",
    "df2 = pd.read_csv(\"day2_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrDoS_DNS        100001\n",
      "DrDoS_LDAP       100001\n",
      "DrDoS_SNMP       100001\n",
      "DrDoS_SSDP       100001\n",
      "DrDoS_MSSQL      100000\n",
      "DrDoS_NetBIOS    100000\n",
      "DrDoS_NTP        100000\n",
      "Syn              100000\n",
      "UDP-lag          100000\n",
      "DrDoS_UDP         99999\n",
      "TFTP              99999\n",
      "BENIGN            56863\n",
      "WebDDoS             439\n",
      "Name:  Label, dtype: int64\n",
      "Syn        200005\n",
      "UDP        199999\n",
      "NetBIOS    199998\n",
      "MSSQL      124392\n",
      "LDAP       109932\n",
      "Portmap    100000\n",
      "BENIGN      56965\n",
      "UDPLag       1873\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1[\" Label\"].value_counts())\n",
    "print(df2[\" Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove socket information and timestamp\n",
    "drop_cols = ['Flow ID', ' Source IP', ' Source Port', ' Destination IP',' Destination Port', ' Timestamp']\n",
    "\n",
    "df1 = df1.drop(drop_cols, axis=1)\n",
    "df2 = df2.drop(drop_cols, axis=1)\n",
    "\n",
    "# remove infinity values\n",
    "df1 = df1.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "\n",
    "# replace invalid SimilarHTTP values with NaN\n",
    "for col in df1.columns:\n",
    "    if col != \" Label\":\n",
    "        df1[col] = pd.to_numeric(df1[col], errors='coerce')\n",
    "\n",
    "# Repeat with multiclass dataset\n",
    "df2 = df2.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "\n",
    "for col in df2.columns:\n",
    "    if col != \" Label\":\n",
    "        df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
    "\n",
    "# drop remaining NaN values from both\n",
    "df1 = df1.dropna(axis=0)\n",
    "df2 = df2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrDoS_SNMP       99788\n",
      "DrDoS_NTP        99404\n",
      "DrDoS_UDP        98687\n",
      "DrDoS_SSDP       98400\n",
      "DrDoS_LDAP       98268\n",
      "DrDoS_MSSQL      97266\n",
      "TFTP             97162\n",
      "DrDoS_DNS        96801\n",
      "DrDoS_NetBIOS    96793\n",
      "UDP-lag          90049\n",
      "Syn              87308\n",
      "BENIGN           54369\n",
      "WebDDoS            322\n",
      "Name:  Label, dtype: int64\n",
      "UDP        197434\n",
      "NetBIOS    190701\n",
      "Syn        184986\n",
      "MSSQL      120069\n",
      "LDAP       107638\n",
      "Portmap     94849\n",
      "BENIGN      54581\n",
      "UDPLag       1873\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1[\" Label\"].value_counts())\n",
    "print(df2[\" Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now balance the samples and create our binary and multiclass datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get benign samples from Day 2 and cull them to the lowest number of attack samples found in Day 1 (excluding webddos)\n",
    "day2ben = df1[df1[\" Label\"] == \"BENIGN\"].copy()\n",
    "day2ben = day2ben.sample(n=50000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BENIGN' 'LDAP' 'NetBIOS' 'MSSQL' 'Portmap' 'Syn' 'UDP' 'UDPLag']\n"
     ]
    }
   ],
   "source": [
    "# get list of labels so we can pull an equal number of samples from each.\n",
    "cols = df2[\" Label\"].unique()\n",
    "print(df2[\" Label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENIGN     50000\n",
      "LDAP       50000\n",
      "NetBIOS    50000\n",
      "MSSQL      50000\n",
      "Portmap    50000\n",
      "Syn        50000\n",
      "UDP        50000\n",
      "UDPLag      1873\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assemble equal number of samples. Will be restructured in multiclass and binary datasets.\n",
    "outMult = None\n",
    "\n",
    "for val in cols:\n",
    "\n",
    "    # too small, so we drop it\n",
    "    if val == 'UDPLag':\n",
    "        slice = df2[df2[\" Label\"] == val].copy()\n",
    "\n",
    "    # replace benign with day 2.\n",
    "    elif val == \"BENIGN\":\n",
    "        slice = day2ben\n",
    "\n",
    "    # get all attacks of this type and cull to appropriate number\n",
    "    else:\n",
    "        slice = df2[df2[\" Label\"] == val].copy()\n",
    "        slice = slice.sample(n=50000,random_state=42) # Ensure equal sample number\n",
    "\n",
    "    # add to output\n",
    "    if outMult is None:\n",
    "        outMult = slice\n",
    "    else:\n",
    "        outMult = pd.concat([outMult, slice])\n",
    "\n",
    "print(outMult[\" Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>SimillarHTTP</th>\n",
       "      <th>Inbound</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22951</th>\n",
       "      <td>6</td>\n",
       "      <td>665498</td>\n",
       "      <td>48</td>\n",
       "      <td>59</td>\n",
       "      <td>4430.0</td>\n",
       "      <td>9674.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.291667</td>\n",
       "      <td>139.362829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39086</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53068</th>\n",
       "      <td>17</td>\n",
       "      <td>20912</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43265</th>\n",
       "      <td>6</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45432</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>21.920310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Protocol   Flow Duration   Total Fwd Packets   Total Backward Packets  \\\n",
       "22951          6          665498                  48                       59   \n",
       "39086         17              14                   4                        0   \n",
       "53068         17           20912                   2                        2   \n",
       "43265          6             152                   1                        2   \n",
       "45432          6               1                   2                        0   \n",
       "\n",
       "       Total Length of Fwd Packets   Total Length of Bwd Packets  \\\n",
       "22951                       4430.0                        9674.0   \n",
       "39086                        804.0                           0.0   \n",
       "53068                         64.0                         204.0   \n",
       "43265                          0.0                           0.0   \n",
       "45432                         31.0                           0.0   \n",
       "\n",
       "        Fwd Packet Length Max   Fwd Packet Length Min  \\\n",
       "22951                   517.0                     0.0   \n",
       "39086                   201.0                   201.0   \n",
       "53068                    32.0                    32.0   \n",
       "43265                     0.0                     0.0   \n",
       "45432                    31.0                     0.0   \n",
       "\n",
       "        Fwd Packet Length Mean   Fwd Packet Length Std  ...   Active Std  \\\n",
       "22951                92.291667              139.362829  ...          0.0   \n",
       "39086               201.000000                0.000000  ...          0.0   \n",
       "53068                32.000000                0.000000  ...          0.0   \n",
       "43265                 0.000000                0.000000  ...          0.0   \n",
       "45432                15.500000               21.920310  ...          0.0   \n",
       "\n",
       "        Active Max   Active Min  Idle Mean   Idle Std   Idle Max   Idle Min  \\\n",
       "22951          0.0          0.0        0.0        0.0        0.0        0.0   \n",
       "39086          0.0          0.0        0.0        0.0        0.0        0.0   \n",
       "53068          0.0          0.0        0.0        0.0        0.0        0.0   \n",
       "43265          0.0          0.0        0.0        0.0        0.0        0.0   \n",
       "45432          0.0          0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       SimillarHTTP   Inbound   Label  \n",
       "22951           0.0         0  BENIGN  \n",
       "39086           0.0         1  BENIGN  \n",
       "53068           0.0         0  BENIGN  \n",
       "43265           0.0         1  BENIGN  \n",
       "45432           0.0         0  BENIGN  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outBin = outMult.drop([\"Unnamed: 0.1\", \"Unnamed: 0\"], axis= 1)\n",
    "outBin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outBin.to_csv(\"testing_set.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4593b52a31704b5155580280f0f05a500adb36bf97584c7e94e26dfe17ea16d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
